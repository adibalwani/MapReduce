Prerequisites to run on local cluster:

1. Make sure you have spark installed and set the environment variables
2. Input data (i.e. all folder after extracting tar.gz) must be present at current working directory (where make commands are being executed). Current folder should be like : all/xxx.csv.gz

Prerequisites to run on EMR (Optional):

1. We are assuming that jobs are being run at your EMR 
2. In your aws configure make sure your output format is "json". We are using json parser in our script so if aws output is text then there will be a problem.
Type aws configure on command prompt
	AccessId : Enter 
	SecretKey : Enter
	region : us-west-2
	output format : json
3. Keep all folder in your current working directory frome where you will call make emr. 
4. We are pushing input data to your S3 bucket from our script. In case internet connection losses or problem happens please upload 
   input data to S3://adibpuri6/input. Output gets generated at s3://adibpuri6/output

=================================== Run ======================================

make run : It will download the dependencies required to compile scala program and then run it locally
