Latex Prerequisitives:
1. sudo apt-get install texlive-latex-base
2. pdflatex --enable-write18 report.tex

Prerequisites to run on local cluster (Optional):

1. export HADOOP_CLASSPATH=.:`hadoop classpath`
2. sudo apt-get install r-cran-ggplot2 
3. If a tmp directory path is specified in core-site.xml, then please delete that tmp folder.
If no path is specified(as per instructions), then the script will handle deletions 
4. export HADOOP_HOME=/usr/local/hadoop
5. export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin
6. Other basic hadoop setup on local machine (make sure datanode and namenode are running properly)
7. Input data (i.e. all folder after extracting tar.gz) must be present at current working directory (where make commands are being executed)

Prerequisites to run on EMR:

1. We are assuming that jobs are being run at your EMR 
2. In your aws configure make sure your output format is "json". We are using json parser in our script so if aws output is text then there will be a problem.
Type aws configure on command prompt
	AccessId : Enter 
	SecretKey : Enter
	region : us-west-2
	output format : json
3. Keep all folder in your current working directory frome where you will call make emr.   
4. We are pushing input data to your S3 bucket from our script. In case internet connection losses or problem happens please upload 
   input data to S3://adibrachit/input. Output gets generated at s3://adibrachit/output

=================================== Run ======================================

make emr : It will run your code on EMR cluster

optional -> make pseuso : It will create a HDFS file system, start hadoop, run your job, get the output and produce the graph on local system

==============================================================================
